# ===============================
# Orpheus TTS FastAPI Configuration
# ===============================
# Copy this file to .env and modify the values as needed
# All values shown here are the defaults used when environment variables are not set

# ===============================
# MODEL CONFIGURATION
# ===============================

# Model name from HuggingFace or local path
TTS_MODEL_NAME="canopylabs/orpheus-tts-0.1-finetune-prod"

# Data type for model weights and computation
# Options: bfloat16 (default), float16, float32, bf16, fp16, fp32
# bfloat16: Best balance of quality and VRAM usage (recommended)
# float16: Slightly lower VRAM, may have numerical issues
# float32: Highest quality but uses more VRAM
TTS_DTYPE="bfloat16"

# Maximum sequence length (prompt + generated tokens)
# Larger values use more VRAM but allow longer text processing
# Recommended: 6144-8192 for most use cases
TTS_MAX_MODEL_LEN="8192"

# Number of GPUs to use for tensor parallelism
# Set to 1 for single GPU setups
TTS_TENSOR_PARALLEL_SIZE="1"

# Fraction of GPU memory to use (0.0 to 1.0)
# Recommendations by GPU:
# - RTX 3090/4090 (24GB): 0.9
# - RTX A6000 (48GB): 0.5-0.6 
# - H100 (80GB): 0.3-0.4
TTS_GPU_MEMORY_UTILIZATION="0.9"

# ===============================
# PERFORMANCE CONFIGURATION
# ===============================

# Thread pool size for file I/O
# Recommended: 4-16 based on CPU cores
TTS_MAX_WORKERS="16"

# ===============================
# GENERATION PARAMETERS (DEFAULTS)
# ===============================
# These are used as defaults when not specified in API requests
# Individual requests can override these values

# Temperature for sampling (0.0 to 2.0)
# Lower values (0.1-0.3) = more deterministic/consistent
# Higher values (0.5-1.0) = more creative/varied
# Default 0.2 works well for TTS
TTS_TEMPERATURE="0.2"

# Top-p nucleus sampling (0.0 to 1.0) 
# Lower values = more focused/predictable
# Higher values = more diverse outputs
# Default 0.9 provides good quality
TTS_TOP_P="0.9"

# Repetition penalty (0.5 to 2.0)
# Values > 1.0 discourage repetition
# Values < 1.0 encourage repetition
# Default 1.1 prevents excessive repetition
TTS_REPETITION_PENALTY="1.1"

# Maximum tokens to generate per request
# Higher values allow longer audio but use more VRAM/time
# Must be less than TTS_MAX_MODEL_LEN minus prompt length
TTS_MAX_TOKENS="4096"

# ===============================
# LOGGING AND DEBUG
# ===============================

# Logging level: DEBUG, INFO, WARNING, ERROR
# DEBUG: Verbose logging including sampling parameters
# INFO: Standard operational logging (recommended)
# WARNING: Only warnings and errors
# ERROR: Only errors
LOG_LEVEL="INFO"

# ===============================
# ADDITIONAL vLLM/SYSTEM SETTINGS
# ===============================

# Force vLLM V0 engine for stability (recommended)
VLLM_USE_V1="0"

# SNAC decoder device (cuda/ cpu/ mps)
# Use cuda if you have sufficient VRAM, cpu otherwise
SNAC_DEVICE="cuda"

# Specify which GPU to use (for multi-GPU systems)
# CUDA_VISIBLE_DEVICES="0"

# ===============================
# USAGE EXAMPLES
# ===============================

# High Quality Setup (requires 24GB+ VRAM):
# TTS_DTYPE="float32"
# TTS_GPU_MEMORY_UTILIZATION="0.95"
# TTS_MAX_MODEL_LEN="8192"

# Memory Efficient Setup (16-20GB VRAM):
# TTS_DTYPE="bfloat16" 
# TTS_GPU_MEMORY_UTILIZATION="0.8"
# TTS_MAX_MODEL_LEN="6144"

# Creative/Varied Output:
# TTS_TEMPERATURE="0.5"
# TTS_TOP_P="0.95"
# TTS_REPETITION_PENALTY="1.2"

# Deterministic/Consistent Output:
# TTS_TEMPERATURE="0.1"
# TTS_TOP_P="0.8"
# TTS_REPETITION_PENALTY="1.0"
